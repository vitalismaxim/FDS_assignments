{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:04.902740Z",
     "start_time": "2020-03-23T15:55:04.876252Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 15:14:53.812310: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-02 15:14:54.513140: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-02 15:14:54.513191: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-02 15:14:54.607079: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-02 15:14:56.042613: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-02 15:14:56.042915: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-02 15:14:56.042925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/tmp/ipykernel_3582/2257262447.py:21: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from textblob import TextBlob\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from finbert.finbert import *\n",
    "import finbert.utils as tools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "project_dir = Path.cwd().parent\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:05.711210Z",
     "start_time": "2020-03-23T15:55:05.693609Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting path variables:\n",
    "1. `lm_path`: the path for the pre-trained language model (If vanilla Bert is used then no need to set this one).\n",
    "2. `cl_path`: the path where the classification model is saved.\n",
    "3. `cl_data_path`: the path of the directory that contains the data files of `train.csv`, `validation.csv`, `test.csv`.\n",
    "---\n",
    "\n",
    "In the initialization of `bertmodel`, we can either use the original pre-trained weights from Google by giving `bm = 'bert-base-uncased`, or our further pre-trained language model by `bm = lm_path`\n",
    "\n",
    "\n",
    "---\n",
    "All of the configurations with the model is controlled with the `config` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:07.405597Z",
     "start_time": "2020-03-23T15:55:07.386378Z"
    }
   },
   "outputs": [],
   "source": [
    "lm_path = 'ProsusAI/finbert'\n",
    "#cl_path = 'finbert-sentiment'\n",
    "cl_path = project_dir/'resources'/'models'/'classifier_model'/'finbert-sentiment'\n",
    "cl_data_path = project_dir/'data'/'sentiment_data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Configuring training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the explanations of the training parameters in the class docsctrings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:12.378583Z",
     "start_time": "2020-03-23T15:55:09.196746Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean the cl_path\n",
    "try:\n",
    "    shutil.rmtree(cl_path) \n",
    "except:\n",
    "    pass\n",
    "\n",
    "bertmodel = AutoModelForSequenceClassification.from_pretrained(lm_path,cache_dir=None, num_labels=3)\n",
    "\n",
    "\n",
    "config = Config(   data_dir=cl_data_path,\n",
    "                   bert_model=bertmodel,\n",
    "                   num_train_epochs=4,\n",
    "                   model_dir=cl_path,\n",
    "                   max_seq_length = 48,\n",
    "                   train_batch_size = 32,\n",
    "                   learning_rate = 2e-5,\n",
    "                   output_mode='classification',\n",
    "                   warm_up_proportion=0.2,\n",
    "                   local_rank=-1,\n",
    "                   discriminate=True,\n",
    "                   gradual_unfreeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`finbert` is our main class that encapsulates all the functionality. The list of class labels should be given in the prepare_model method call with label_list parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:16.657078Z",
     "start_time": "2020-03-23T15:55:16.639644Z"
    }
   },
   "outputs": [],
   "source": [
    "finbert = FinBert(config)\n",
    "finbert.base_model = lm_path\n",
    "finbert.config.discriminate=True\n",
    "finbert.config.gradual_unfreeze=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:17.850734Z",
     "start_time": "2020-03-23T15:55:17.368073Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/02/2022 15:15:00 - INFO - finbert.finbert -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False\n"
     ]
    }
   ],
   "source": [
    "finbert.prepare_model(label_list=['positive','negative','neutral'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:19.395707Z",
     "start_time": "2020-03-23T15:55:19.349642Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the training examples\n",
    "train_data = finbert.get_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:55:25.912424Z",
     "start_time": "2020-03-23T15:55:20.065887Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxim/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = finbert.create_the_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Fine-tune only a subset of the model\n",
    "The variable `freeze` determines the last layer (out of 12) to be freezed. You can skip this part if you want to fine-tune the whole model.\n",
    "\n",
    "<span style=\"color:red\">Important: </span>\n",
    "Execute this step if you want a shorter training time in the expense of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for fine-tuning a subset of the model.\n",
    "\n",
    "freeze = 6\n",
    "\n",
    "for param in model.bert.embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for i in range(freeze):\n",
    "    for param in model.bert.encoder.layer[i].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:58:35.486890Z",
     "start_time": "2020-03-23T15:55:27.293772Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
      "10/02/2022 15:15:01 - INFO - finbert.utils -   *** Example ***\n",
      "10/02/2022 15:15:01 - INFO - finbert.utils -   guid: train-1\n",
      "10/02/2022 15:15:01 - INFO - finbert.utils -   tokens: [CLS] first would like cong ##rat ##ulate excel ##len ##cy trek ##i ##en ex ##tre ##mist ##s region beyond full confidence full commitment family afghanistan able overcome legacy decades violence suffering restore historic position model cooperation different cultures regional crossroads hub trade transit transportation tourism asian continent [SEP]\n",
      "10/02/2022 15:15:01 - INFO - finbert.utils -   input_ids: 101 2034 2052 2066 26478 8609 9869 24970 7770 5666 10313 2072 2368 4654 7913 23738 2015 2555 3458 2440 7023 2440 8426 2155 7041 2583 9462 8027 5109 4808 6114 9239 3181 2597 2944 6792 2367 8578 3164 16760 9594 3119 6671 5193 6813 4004 9983 102\n",
      "10/02/2022 15:15:01 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "10/02/2022 15:15:01 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "10/02/2022 15:15:01 - INFO - finbert.utils -   label: positive (id = 0)\n",
      "10/02/2022 15:15:06 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "10/02/2022 15:15:06 - INFO - finbert.finbert -     Num examples = 1045\n",
      "10/02/2022 15:15:06 - INFO - finbert.finbert -     Batch size = 32\n",
      "10/02/2022 15:15:06 - INFO - finbert.finbert -     Num steps = 24\n",
      "Epoch:   0%|                                              | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78aaf7d9d5f4440c9a17a5d90eea3e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/02/2022 15:17:06 - INFO - finbert.utils -   *** Example ***\n",
      "10/02/2022 15:17:06 - INFO - finbert.utils -   guid: validation-1\n",
      "10/02/2022 15:17:06 - INFO - finbert.utils -   tokens: [CLS] honour stand prestigious ro ##st ##rum today represent fellow country ##wo experience freedoms opportunities democracy sacrificed much build afghan truly able live peace freedom day every single afghan lives peace freedom day live work — day know achieve solidarity international friends partners day longer hope believe [SEP]\n",
      "10/02/2022 15:17:06 - INFO - finbert.utils -   input_ids: 101 6225 3233 8919 20996 3367 6824 2651 5050 3507 2406 12155 3325 22467 6695 7072 20268 2172 3857 12632 5621 2583 2444 3521 4071 2154 2296 2309 12632 3268 3521 4071 2154 2444 2147 1517 2154 2113 6162 14657 2248 2814 5826 2154 2936 3246 2903 102\n",
      "10/02/2022 15:17:06 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "10/02/2022 15:17:06 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "10/02/2022 15:17:06 - INFO - finbert.utils -   label: neutral (id = 2)\n",
      "10/02/2022 15:17:07 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "10/02/2022 15:17:07 - INFO - finbert.finbert -     Num examples = 197\n",
      "10/02/2022 15:17:07 - INFO - finbert.finbert -     Batch size = 32\n",
      "10/02/2022 15:17:07 - INFO - finbert.finbert -     Num steps = 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4794939e42fb428cb92ce668c71a96e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation losses: [1.186575940677098]\n",
      "No best model found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|█████████▎                           | 1/4 [02:15<06:45, 135.24s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a275a5fa5b54793b582ff1af71d446c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/02/2022 15:19:44 - INFO - finbert.utils -   *** Example ***\n",
      "10/02/2022 15:19:44 - INFO - finbert.utils -   guid: validation-1\n",
      "10/02/2022 15:19:44 - INFO - finbert.utils -   tokens: [CLS] honour stand prestigious ro ##st ##rum today represent fellow country ##wo experience freedoms opportunities democracy sacrificed much build afghan truly able live peace freedom day every single afghan lives peace freedom day live work — day know achieve solidarity international friends partners day longer hope believe [SEP]\n",
      "10/02/2022 15:19:44 - INFO - finbert.utils -   input_ids: 101 6225 3233 8919 20996 3367 6824 2651 5050 3507 2406 12155 3325 22467 6695 7072 20268 2172 3857 12632 5621 2583 2444 3521 4071 2154 2296 2309 12632 3268 3521 4071 2154 2444 2147 1517 2154 2113 6162 14657 2248 2814 5826 2154 2936 3246 2903 102\n",
      "10/02/2022 15:19:44 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "10/02/2022 15:19:44 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "10/02/2022 15:19:44 - INFO - finbert.utils -   label: neutral (id = 2)\n",
      "10/02/2022 15:19:45 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "10/02/2022 15:19:45 - INFO - finbert.finbert -     Num examples = 197\n",
      "10/02/2022 15:19:45 - INFO - finbert.finbert -     Batch size = 32\n",
      "10/02/2022 15:19:45 - INFO - finbert.finbert -     Num steps = 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6bbd418d1f43b3bb22aeb0a925162a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation losses: [1.186575940677098, 1.0806583166122437]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|██████████████████▌                  | 2/4 [04:53<04:57, 148.53s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4c201c8b0743c09991fdbbd4641913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/02/2022 15:22:38 - INFO - finbert.utils -   *** Example ***\n",
      "10/02/2022 15:22:38 - INFO - finbert.utils -   guid: validation-1\n",
      "10/02/2022 15:22:38 - INFO - finbert.utils -   tokens: [CLS] honour stand prestigious ro ##st ##rum today represent fellow country ##wo experience freedoms opportunities democracy sacrificed much build afghan truly able live peace freedom day every single afghan lives peace freedom day live work — day know achieve solidarity international friends partners day longer hope believe [SEP]\n",
      "10/02/2022 15:22:38 - INFO - finbert.utils -   input_ids: 101 6225 3233 8919 20996 3367 6824 2651 5050 3507 2406 12155 3325 22467 6695 7072 20268 2172 3857 12632 5621 2583 2444 3521 4071 2154 2296 2309 12632 3268 3521 4071 2154 2444 2147 1517 2154 2113 6162 14657 2248 2814 5826 2154 2936 3246 2903 102\n",
      "10/02/2022 15:22:38 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "10/02/2022 15:22:38 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "10/02/2022 15:22:38 - INFO - finbert.utils -   label: neutral (id = 2)\n",
      "10/02/2022 15:22:39 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "10/02/2022 15:22:39 - INFO - finbert.finbert -     Num examples = 197\n",
      "10/02/2022 15:22:39 - INFO - finbert.finbert -     Batch size = 32\n",
      "10/02/2022 15:22:39 - INFO - finbert.finbert -     Num steps = 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd3a46353724c7d9d25405857c88647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|███████████████████████████▊         | 3/4 [07:45<02:39, 159.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation losses: [1.186575940677098, 1.0806583166122437, 1.1422536543437414]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c1a88b84014ccea368e1b701e6f706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/02/2022 15:26:08 - INFO - finbert.utils -   *** Example ***\n",
      "10/02/2022 15:26:08 - INFO - finbert.utils -   guid: validation-1\n",
      "10/02/2022 15:26:08 - INFO - finbert.utils -   tokens: [CLS] honour stand prestigious ro ##st ##rum today represent fellow country ##wo experience freedoms opportunities democracy sacrificed much build afghan truly able live peace freedom day every single afghan lives peace freedom day live work — day know achieve solidarity international friends partners day longer hope believe [SEP]\n",
      "10/02/2022 15:26:08 - INFO - finbert.utils -   input_ids: 101 6225 3233 8919 20996 3367 6824 2651 5050 3507 2406 12155 3325 22467 6695 7072 20268 2172 3857 12632 5621 2583 2444 3521 4071 2154 2296 2309 12632 3268 3521 4071 2154 2444 2147 1517 2154 2113 6162 14657 2248 2814 5826 2154 2936 3246 2903 102\n",
      "10/02/2022 15:26:08 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "10/02/2022 15:26:08 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "10/02/2022 15:26:08 - INFO - finbert.utils -   label: neutral (id = 2)\n",
      "10/02/2022 15:26:09 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "10/02/2022 15:26:09 - INFO - finbert.finbert -     Num examples = 197\n",
      "10/02/2022 15:26:09 - INFO - finbert.finbert -     Batch size = 32\n",
      "10/02/2022 15:26:09 - INFO - finbert.finbert -     Num steps = 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6943e5afa9574cdc85df8e0627dd5216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████████████| 4/4 [11:16<00:00, 169.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation losses: [1.186575940677098, 1.0806583166122437, 1.1422536543437414, 1.1106150150299072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model = finbert.train(train_examples = train_data, model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "`bert.evaluate` outputs the DataFrame, where true labels and logit values for each example is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:58:40.056789Z",
     "start_time": "2020-03-23T15:58:40.023198Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = finbert.get_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:58:48.248044Z",
     "start_time": "2020-03-23T15:58:41.699009Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/02/2022 15:26:24 - INFO - finbert.utils -   *** Example ***\n",
      "10/02/2022 15:26:24 - INFO - finbert.utils -   guid: test-1\n",
      "10/02/2022 15:26:24 - INFO - finbert.utils -   tokens: [CLS] stand general assembly today reminded wise men women displayed unique capacity messages love peace hope afghanistan yet asian crossroads dialogue among civilizations model harmony culture tolerance engagement confident plans programmes self - reliance reform bo ##lster ##ed commitment international partners chart path towards realizing full potential [SEP]\n",
      "10/02/2022 15:26:24 - INFO - finbert.utils -   input_ids: 101 3233 2236 3320 2651 6966 7968 2273 2308 6913 4310 3977 7696 2293 3521 3246 7041 2664 4004 16760 7982 2426 24784 2944 9396 3226 13986 8147 9657 3488 8497 2969 1011 17975 5290 8945 29576 2098 8426 2248 5826 3673 4130 2875 9301 2440 4022 102\n",
      "10/02/2022 15:26:24 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "10/02/2022 15:26:24 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "10/02/2022 15:26:24 - INFO - finbert.utils -   label: neutral (id = 2)\n",
      "10/02/2022 15:26:25 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "10/02/2022 15:26:25 - INFO - finbert.finbert -     Num examples = 228\n",
      "10/02/2022 15:26:25 - INFO - finbert.finbert -     Batch size = 32\n",
      "10/02/2022 15:26:25 - INFO - finbert.finbert -     Num steps = 28\n",
      "10/02/2022 15:26:25 - INFO - finbert.finbert -   ***** Running evaluation ***** \n",
      "10/02/2022 15:26:25 - INFO - finbert.finbert -     Num examples = 228\n",
      "10/02/2022 15:26:25 - INFO - finbert.finbert -     Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b265efd6bc84d76a303b438d2167d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = finbert.evaluate(examples=test_data, model=trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:58:51.361079Z",
     "start_time": "2020-03-23T15:58:51.339548Z"
    }
   },
   "outputs": [],
   "source": [
    "def report(df, cols=['label','prediction','logits']):\n",
    "    #print('Validation loss:{0:.2f}'.format(metrics['best_validation_loss']))\n",
    "    cs = CrossEntropyLoss(weight=finbert.class_weights)\n",
    "    loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n",
    "    print(\"Loss:{0:.2f}\".format(loss))\n",
    "    print(\"Accuracy:{0:.2f}\".format((df[cols[0]] == df[cols[1]]).sum() / df.shape[0]) )\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(df[cols[0]], df[cols[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:58:53.190447Z",
     "start_time": "2020-03-23T15:58:53.166729Z"
    }
   },
   "outputs": [],
   "source": [
    "results['prediction'] = results.predictions.apply(lambda x: np.argmax(x,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T15:58:54.436270Z",
     "start_time": "2020-03-23T15:58:54.399174Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:1.11\n",
      "Accuracy:0.22\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.11      0.17        97\n",
      "           1       0.11      0.65      0.19        26\n",
      "           2       0.51      0.21      0.30       105\n",
      "\n",
      "    accuracy                           0.22       228\n",
      "   macro avg       0.33      0.33      0.22       228\n",
      "weighted avg       0.40      0.22      0.23       228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3582/1393610332.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n"
     ]
    }
   ],
   "source": [
    "report(results,cols=['labels','prediction','predictions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
